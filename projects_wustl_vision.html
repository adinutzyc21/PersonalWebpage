<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
    <title>Adina Raluca Stoica - Other Projects</title>
    <link rel="stylesheet" href="style.css" type="text/css" media="all" />
    <link rel="stylesheet" href="menu_style.css" type="text/css" media="all" />
    <script type="text/javascript">
        <!-- //Google analytics
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-45332602-1', 'wustl.edu');
        ga('send', 'pageview');
        //-->
    </script>

</head>

<body>

    <div id="header">
        <p><a href="index.html">Adina Raluca Stoica</a></p>
    </div>

    <ul id="menu-bar">
        <li><a href="index.html">About Me</a></li>
        <li><a href="resume.html">Resume</a></li>
        <li><a href="code.html">Code</a></li>
        <li><a href="research.html">Research</a>
            <ul>
                <li><a href="research_merl.html">Mitsubishi Research</a></li>
                <li><a href="research_wustl.html">Washington University</a></li>
                <li><a href="research_sproj.html">Senior Project</a></li>
                <li><a href="research_clemson.html">Clemson University</a></li>
                <li><a href="research_houston.html">University of Houston</a></li>
                <li><a href="research_bard.html">Bard College</a></li>
            </ul>
        </li>
        <li class="active"><a href="projects.html">Projects</a>
            <ul>
                <li class="not_active"><a href="projects_idea.html">Idea Labs</a></li>
                <li class="active"><a href="projects_wustl.html">Wash U Courses</a></li>
                <li class="not_active"><a href="projects_bgia.html">BGIA Essays</a></li>
                <li class="not_active"><a href="projects_bard.html">Bard Courses</a></li>
                <li class="not_active"><a href="projects_echo.html">ECHO Company</a></li>
            </ul>
        </li>
        <li><a href="personal.html">Personal</a>
            <ul>
                <li><a href="personal_writing.html">Selected Writing</a></li>
                <li><a href="personal_essays.html">Admission Essays</a></li>
                <li><a href="personal_pictures.html">Selected Pictures</a></li>
            </ul>
        </li>
        <li><a href="contact.html">Contact</a></li>
    </ul>

    <div class="info">
        <!-- VISION-->
        <h2><a href="projects.html">Projects</a> > <a href="projects_wustl.html">Wash U Courses</a> > Computer Vision </h2>
        <i>Washington University in St. Louis, Spring 2012</i><br /><br />

        <a href="extras/proj/computer_vision/hybrid.jpg" target="_blank"> <img alt="Picture" src="extras/proj/computer_vision/hybrid.jpg" width="150" style="float:left; margin-right:20px"></a>
        <h3>Project 1. Hybrid Images</h3><br/> This project uses a modification of the approach described in the SIGGRAPH 2006 <a target="_blank" href="http://cvcl.mit.edu/publications/OlivaTorralb_Hybrid_Siggraph06.pdf">paper</a> by Oliva, Torralba, and
        Schyns.<br/> The purpose of this project was to create hybrid images, which are static images that have two interpretations, which change as a function of viewing distance. Because of the way human visual perception works, the images seem to change
        as the viewing distance changes. High frequency tends to dominate perception when it is available, but, at a distance, only the low frequency (smooth) part of the signal can be seen. Alternatively, one can say that what we perceive in the image
        changes as the image increases or decreases in size.
        <br/><br/>
        <h3>Project 2. Image Mosaicing </h3><br/>
        <a href="extras/proj/computer_vision/mosaic.jpg" target="_blank"> <img alt="Picture" src="extras/proj/computer_vision/mosaic.jpg" width="200" style="float:right; margin-left:20px"></a>
        This was a team project. Using two pictures of the same scene that have overlapping parts, we create the panorama. The workflow for the image mosaicing includes detecting SIFT features, computing the possible matches of the SIFT features, detecting the
        best feature matches and the best homography matrix using RANSAC and stitching the two images so that the matched points overlap. As extensions we implemented image stitching with cylindical mapping and mosaic blending.
        <br/><br/>
        <h3>Project 3. PCA-Based Face Recognition </h3><br/> This was a team project too. We used images in the AT&T face database in order to implement a face recognition program based on Principal Component Analysis (PCA). The AT&T face database contains
        40 subjects, each having 10 pictures taken from various poses. We used 9 of these images as training data, and the last one for testing purposes. Testing was done versus both all the images in the training dataset, as well as versus each subject's
        mean image in the dataset. The success rate with 4 principal components on all images in the dataset was 80%.
        <br/><br/>
        <h3>Project 4. Single Image Haze Removal Using Dark Channel Prior </h3><br/>
        <a href="extras/proj/computer_vision/ny_res.jpg" target="_blank"> <img alt="Picture" src="extras/proj/computer_vision/ny_res.jpg" width="150" style="float:right; margin-left:20px"></a>
        <a href="extras/proj/computer_vision/ny_orig.jpg" target="_blank"> <img alt="Picture" src="extras/proj/computer_vision/ny_orig.jpg" width="150" style="float:right; margin-left:20px"></a>
        In a team, implemented the Single Image Haze Removal Using Dark Channel Prior <a target="_blank" href="http://research.microsoft.com/en-us/um/people/jiansun/papers/dehaze_cvpr2009.pdf">paper</a>. In the paper, He, Sun and Tang describe a procedure
        for removing haze from a single input image using the dark channel prior. The most widely used model to describe the formation of a haze image is:<br/> I(x) = J(x)t(x) + A(1 - t(x)) <br/> where I is the observed image intensity, J is the scene
        radiance, A is the global atmospheric light and t is the medium transmission, describing the portion of light that reaches the camera. The goal of haze removal is to recover A, J and t from I.<br/> The paper sets out to compute the Dark Channel
        Prior, estimate the Atmospheric Light A based on it, use this estimated A to estimate transmission t. This transmission is then refined using Soft Matting and the Scene Radiance J is recovered using the results. <br/>
        <br/><br/>

        <a href="https://github.com/adinutzyc21/ComputerVision" target="_blank"><img alt="Picture" src="images/github.jpg" height="80" class="image_left" /></a>
        <p class="tab_left">I wrote a more detailed page for this course <a href="https://sites.google.com/site/computervisionadinastoica/" target="_blank"> here</a>, where you can read more about the project requirements and results for every project. </p>
        <p class="tab_left">Special thanks to Derek for working with me on the code for Projects 2, 3 and 4 </p>
        <p class="tab_left">You can find the code for the course on my <a href="https://github.com/adinutzyc21/ComputerVision" target="_blank">GitHub</a>.</p>
        <br/>
    </div>
    <!--info-->
    <div class="clear"> </div>

    <footer>
        <p align="center">Copyright &#169; 2011-2017 Adina Raluca Stoica (<a href="contact.html">contact me</a>). All rights reserved. </p>
    </footer>
</body>

</html>